\chapter{Implementation details} \label{chap:impl}

\section*{}

% Este capítulo pode ser dedicado à apresentação de detalhes de nível
% mais baixo relacionados com o enquadramento e implementação das
% soluções preconizadas no capítulo anterior.
% Note-se no entanto que detalhes desnecessários à compreensão do
% trabalho devem ser remetidos para anexos.

This chapter ...
% TODO

\section{Overview} \label{sec:sol:overview}

\fig{algorithm-flow}{Implemented library modules overview.}

In order to create an Android application capable of estimating a person's
heart rate, a desktop application was developed because of a faster
implementation speed, and simpler and easier testing. Later, the main part
of this application was integrated into an Android application.

The application was divided into several modules, illustrated in
figure~\ref{fig:algorithm-flow}, which, later, were extracted into an
independent library to be integrated into an Android application.
The language used to implement the desktop application and library
were C/C++. In addition, for the image processing operations, the
computer vision library, OpenCV, was used.

% TODO explain the purpose of some of the modules

\section{\evm{} implementations} \label{sec:impl:evm}

\fig{evm-flow}{\evm{} method steps.}

This section presents the details of several different implementations of the
\evm{} method.

The first implementations, described on sections~\ref{sec:impl:evm:gdownideal},
\ref{sec:impl:evm:gdowniir} and~\ref{sec:impl:evm:lpyriir},
were developed in Java to facilitate the integration into the Android
application. However, the OpenCV Java binding was still in its early stages
which end up creating difficulties for the development. Thus, the final
implementation, on section~\ref{sec:impl:evm:final}, was implemented in C/C++,
which also reduces the number of JNI calls from the Android JVM and
increases the application performance.

The purpose of implementing multiple variants of the method was to study
how the method worked and select which spatial and temporal filters would
better fit the application goal: amplify color variation in real-time.

Figure~\ref{fig:evm-flow} shows generic steps of the method which will be
detailed on each of the following sections. The final step,
\emph{add to original frame}, however, remains the same in all
implementations. Which is when the magnified values are added back to the
original frame in order to obtain the processed frame.

\subsection{EvmGdownIdeal} \label{sec:impl:evm:gdownideal}

This was the first implementation, thus, its goal was to understand how the
method worked, and match the implementation provided, in MATLAB,
by~\cite{Wu2012Eulerian}. However, this implementation would have real-time
support by using a sliding window of $30$ frames.

\begin{description}
  \item[Resize down]\hfill\\
        This step applies a spatial filter by calculating a level of the
        Gaussian pyramid. This is achieved by looping to the desired
        level where the input to the next loop is the result from the previous
        loop, starting with the original frame. A Gaussian pyramid level is
        calculated by, first, convolving the input frame with the kernel:

        \begin{equation}
          \frac{1}{256}
          \begin{bmatrix}
             1 &  4 &  6 &  4 &  1 \\
             4 & 16 & 24 & 16 &  4 \\
             6 & 24 & 36 & 24 &  6 \\
             4 & 16 & 24 & 16 &  4 \\
             1 &  4 &  6 &  4 &  1 \\
          \end{bmatrix}
        \end{equation}

        and then, downsampling the frame by rejecting even rows and columns.

  \item[Temporal filter]\hfill\\
        It was used an ideal bandpass filter to remove any amplification of
        undesired frequency from the color variation of each pixel.
        To construct this ideal filter, the Fourier transform was calculated
        for each pixel over the sliding window of $30$ frames. Then,
        frequencies below $45$ and above $240$ where set to zero, and the frame
        was rebuilt using the inverse Fourier transform.

  \item[Amplification]\hfill\\
        In this step, the result of the temporal filter is multiplied by an
        $\alpha$ value. Which results in the magnification of the color
        variation selected by the temporal filter.

  \item[Resize up]\hfill\\
        This step performs the inverse operation of the \emph{resize down} step,
        where it upsamples the frame by inserting even rows and columns with
        zeros, and then, convolves the input frame with the same kernel
        multiplied by $4$. However, when the original frame is not multiple of
        two, an additional resize operation as to be done in order for the
        upsampled frame to match the original frame's size.
\end{description}

\subsection{EvmGdownIIR} \label{sec:impl:evm:gdowniir}

This implementation is very similar to the one above, but uses a different
temporal filter which does not require a sliding window of frames to support
real-time results. The filter used was an IIR bandpass filter, which was
constructed from the subtraction of two first-order lowpass IIR filters. Each
lowpass filter is computed as follows:

\begin{equation}
  L_n = L_{n-1} * (1 - \omega) + \omega * M
\end{equation}

where $M$ is the current frame, $L$ is the lowpass filter accumulator for
each frame, and $\omega$ is the cutoff frequency percentage.

The IIR temporal bandpass filter demonstrated similar results to the ideal
temporal filter used on the first implementation, without the need for
persisting a sliding window of frames, which simplifies solution and reduces
the computational power required by the device.

\subsection{EvmLpyrIIR} \label{sec:impl:evm:lpyriir}

\fig{Lpyr}{Overview of image deconstruction and reconstruction for building a
Laplacian pyramid.}

Using the same IIR temporal filter as above, this implementation uses
a different spatial filter, which, instead of, computing a level of the
Gaussian pyramid, it constructs the full Laplacian pyramid and then applies
the temporal filter to each of its bands and each band is amplified differently.

\begin{description}
  \item[Resize down]\hfill\\
        Figure~\ref{fig:Lpyr} shows the steps to decompose and reconstruct
        an image for the purpose of building a Laplacian pyramid. The
        \emph{original image} must be decomposed into two images,
        \emph{blurred} and \emph{fine}, by applying any type of spatial lowpass
        filter and scaling the image down or up by 2. In this case, a
        Gaussian filter was applied as described on steps \emph{Resize down}
        and \emph{Resize up} of the first implementation. Further levels of the
        pyramid can be computed by decomposing the \emph{blurred image} in the
        same manner.

  \item[Temporal filter]\hfill\\
        The temporal filter used is the IIR bandpass filter, as described above
        for the previous implementation, only this time it is applied to each
        level of the pyramid.

  \item[Amplification]\hfill\\
        The amplification method in this implementation is more complex than
        the one previously used. It is based on the implementation provided
        by~\cite{Wu2012Eulerian}. It uses a different $\alpha$ value for each
        band of spatial frequencies, which corresponds to the Laplacian pyramid
        levels. The magnification value, $\alpha$, follows the equation:

        \begin{equation}
          (1 + \alpha) \delta(t) < \frac{\lambda}{8}
        \end{equation}

        where $\delta(t)$ represents the displacement function and $\lambda$
        the spatial wavelength. Further details about this equation may be
        found on~\cite[Section 3.2]{Wu2012Eulerian}.

  \item[Resize up]\hfill\\
        This step reconstructs the \emph{original image} by iteratively
        reconstructing each \emph{blurred image} until the now processed
        \emph{original image} is reached.
\end{description}

This implementation demonstrated that by constructing a Laplacian pyramid for
the spatial filter finer motion detail would be revealed, whereas the color
variation, the property to be analyzed, was less evident.

\subsection{Performance optimized EvmGdownIIR} \label{sec:impl:evm:final}

Because the OpenCV Java binding was not complete at the time, the Java desktop
implementations were not executing fast enough for real-time processing. Thus,
a C/C++ implementation of the method that demonstrated better color variation
was developed. In addition, after studying the performance of the application,
detailed on section~\ref{sec:results:perf}, the resize operations proved to be
computationally expensive. Therefore, the \emph{Resize down} and
\emph{Resize up} steps were modified to faster resize operations that did not
alter the resulting image.

\begin{description}
  \item[Resize down]\hfill\\
        This step was changed to a single resize operation using the
        OpenCV interpolation method named \emph{area}, which produces a similar
        result to the one provided by using a Gaussian filter and downsampling
        the image.
        However, instead of, iteratively downsampling the frame multiple times,
        the resize in this step is done in only once to a predefined size.

  \item[Resize up]\hfill\\
        This step was also modified to a single resize operation using the
        linear interpolation method, which produces a good result in short
        amount of time.
\end{description}

\section{Face detection} \label{sec:impl:face}

...
% TODO face detection stabilization
% TODO multiple faces

\section{Signal validations} \label{sec:impl:validations}

...
% TODO raw signal noise
% TODO Pulse wave detection algorithm simplification

\section{Heart rate estimation} \label{sec:impl:estimation}

...
% TODO power spectrum gave better results because peak count was not very consistent
% TODO explain average technique to reduce errors

\section{Performance optimizations} \label{sec:impl:performance}

...
% TODO EVM optimizations
% TODO EVM on face box only
% TODO face detection every 1 second
% TODO only deal with RGB channels instead of RGBA since alpha was constant

\section{Android integration} \label{sec:impl:android}

\fig{android-flow}{Integration workflow between Android native and Java parts.}

...
% TODO usage of JNI and Android NDK
% TODO reimplementation of OpenCV Android:
%      RGB frame, zoom stretch, rotation, camera switch, fps switch

\section{Chapter summary}

...
% TODO
